(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{431:function(t,s,a){"use strict";a.r(s);var n=a(56),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"第-12-章-遍历"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第-12-章-遍历"}},[t._v("#")]),t._v(" 第 12 章：遍历")]),t._v(" "),a("p",[t._v("迄今为止，在我们的容器马戏团中，你曾看到我们驯服了凶猛的 "),a("RouterLink",{attrs:{to:"/ch8.html"}},[t._v("functor")]),t._v("，让它听从我们的意志，执行任何让我们心动的操作；你曾被同时使用"),a("RouterLink",{attrs:{to:"/ch10.html"}},[t._v("函数应用")]),t._v("来收集结果的许多危险作用的杂耍弄得晕头转向；你曾在看到容器通过 "),a("RouterLink",{attrs:{to:"/ch9.html"}},[t._v("join")]),t._v(" 凭空消失时惊讶地坐倒。在副作用杂耍中，我们看到它们经过 compose 合为一体。而最近，我们大胆地超越了自然，在你的眼前将一种类型转化为另一种 ("),a("RouterLink",{attrs:{to:"/ch11.html"}},[t._v("natural transformations")]),t._v(")。")],1),t._v(" "),a("p",[t._v("至于我们的下一个表演，我们要看一下遍历。我们将看着类型在彼此之间翱翔，就像空中飞人一样保持着我们的值不变。我们将像倾斜旋转中的手推车一样重新排列作用 (effects)。当我们的容器像变形金刚的四肢一样交织在一起时，我们可以用这个接口来进行整理。我们将见证不同的作用与不同的顺序。拿上我的长裤和滑动口哨，让我们开始吧。")]),t._v(" "),a("h2",{attrs:{id:"类型与类型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#类型与类型"}},[t._v("#")]),t._v(" 类型与类型")]),t._v(" "),a("p",[t._v("让我们整点怪活：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// readFile :: FileName -> Task Error String")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// firstWords :: String -> String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" firstWords "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("intercalate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("take")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tldr :: FileName -> Task Error String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" tldr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("firstWords"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" readFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("tldr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'file1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'file2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [Task('hail the monarchy'), Task('smash the patriarchy')]")]),t._v("\n")])])]),a("p",[t._v("在这里，我们读了一堆文件然后形成一个无用的 task 数组。要怎么样对其中的每一个进行 fork 操作呢？如果我们能够把类型做一些变化，得到 "),a("code",[t._v("Task Error [String]")]),t._v(" 而不是 "),a("code",[t._v("[Task Error String]")]),t._v(" 的话，想必是极好的。这样，我们将得到一个包含所有结果的 future value（译注：即异步任务完成后返回的值）；从异步的需求来说，这要比多个 future value （分别在各自空闲时间完成任务后再返回）要好操作得多。")]),t._v(" "),a("p",[t._v("这里有最后一个例子，展示一种棘手的情况：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// getAttribute :: String -> Node -> Maybe String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// $ :: Selector -> IO Node")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// getControlNode :: Selector -> IO (Maybe (IO Node))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" getControlNode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("$"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getAttribute")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'aria-controls'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  $\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("看看那些渴望在一起的 "),a("code",[t._v("IO")]),t._v(" 们。如果能把他们 "),a("code",[t._v("join")]),t._v(" 起来，让他们面对面地跳舞，那真是太可爱了。可惜的是，一个 "),a("code",[t._v("Maybe")]),t._v(" 站在他们之间，就像舞会上的陪练。我们最好的办法是把它们的位置移到彼此旁边，这样每种类型最后都可以在一起，我们的签名可以简化为 "),a("code",[t._v("IO (Maybe Node)")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"类型风水"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#类型风水"}},[t._v("#")]),t._v(" 类型风水")]),t._v(" "),a("p",[a("code",[t._v("Traversable")]),t._v(" 接口由两个值得称道的函数组成："),a("code",[t._v("sequence")]),t._v(" 和 "),a("code",[t._v("traverse")]),t._v("。")]),t._v(" "),a("p",[t._v("我们用 "),a("code",[t._v("sequence")]),t._v(" 重新编排编排类型：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("List"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Maybe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'the facts'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// [Just('the facts')]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("a")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("b")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Task(Map({ a: 1, b: 2 }))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("IO")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("IO")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'buckle my shoe'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// IO(Right('buckle my shoe'))")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'wing'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Right(['wing'])")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("left")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'wing'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Task(Left('wing'))")]),t._v("\n")])])]),a("p",[t._v("看清楚这里发生了什么吗？嵌套类型里外翻转了过来，就像潮湿夏夜里的皮裤翻过来了一样。内部的 functor 转移到了外部，而外部的转移到了内部。不过要注意，"),a("code",[t._v("sequence")]),t._v(" 对它的参数有一点挑剔。它看起来像这样子：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// sequence :: (Traversable t, Applicative f) => (a -> f a) -> t (f a) -> f (t a)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" sequence "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("curry")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" x")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我们先看第二个参数。它必须是一个持有 "),a("em",[t._v("Applicative")]),t._v(" 的 "),a("em",[t._v("Traversable")]),t._v("。这听起来很严格，但是事实往往如此。这就是把 "),a("code",[t._v("t (f a)")]),t._v(" 转换成了 "),a("code",[t._v("f (t a)")]),t._v("。还不够明显吗？这两种类型简直就是在背靠背。而第一个参数，它仅仅是一个拐杖，只在无类型的语言中是必要的。它提供了一个类型构造器（即 "),a("em",[t._v("of")]),t._v("）用来倒置那些不情愿被 map 的类型（比如 "),a("code",[t._v("Left")]),t._v("）——稍后会有更多介绍。")]),t._v(" "),a("p",[t._v("使用 "),a("code",[t._v("sequence")]),t._v("，我们可以像在人行道上变戏法一样精确地转移类型。但它是如何工作的呢？让我们看看一个类型，比如说 "),a("code",[t._v("Either")]),t._v("，会如何实现它：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Right")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Either")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("$value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("没错，如果我们的 "),a("code",[t._v("$value")]),t._v(" 是一个 functor （事实上它必须是一个 applicative functor），我们就可以简单地 "),a("code",[t._v("map")]),t._v(" 我们的构造器来实现类型的跃迁。")]),t._v(" "),a("p",[t._v("你可能注意到，我们把 "),a("code",[t._v("of")]),t._v(" 完全忽略掉了。它仅仅是为了在 "),a("code",[t._v("map")]),t._v(" 不可用的情况下而被传入的，比如在 "),a("code",[t._v("Left")]),t._v(" 中：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Left")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Either")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("我们希望这些类型总是以相同的排列结束，所以对于像 "),a("code",[t._v("Left")]),t._v(" 这样的实际上并不持有 applicative functor 的类型来说，我们有必要这么做来让它们获得一点小小的帮助。 "),a("em",[t._v("Applicative")]),t._v(" 接口要求我们首先有一个 "),a("em",[t._v("Pointed Functor")]),t._v("，使得我们总是有一个 "),a("code",[t._v("of")]),t._v(" 来传入。在具有类型系统的语言中，外部的类型可以通过签名被推断而不需要显式地给出。")]),t._v(" "),a("h2",{attrs:{id:"作用组合"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#作用组合"}},[t._v("#")]),t._v(" 作用组合")]),t._v(" "),a("p",[t._v("就我们的容器而言，不同的顺序会带来不同的结果，如果我有一个 "),a("code",[t._v("[Maybe a]")]),t._v("，它是一个包含可能的值的集合 (a collection of possible values)；而如果我有一个 "),a("code",[t._v("Maybe [a]")]),t._v('，那是一个可能的包含值的集合 (a possible collection of values)。前者表示我们会宽容地保留那些"好"的值，而后者则意味着这是一个 "all or nothing" 的情况。类似地，'),a("code",[t._v("Either Error (Task Error a)")]),t._v(" 可以表示一个客户端的验证，而 "),a("code",[t._v("Task Error (Either Error a)")]),t._v(" 则会是一个服务端的验证。类型可以互换，为我们带来不同的作用。")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// fromPredicate :: (a -> Bool) -> a -> Either e a")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// partition :: (a -> Bool) -> [a] -> [Either e a]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("f")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromPredicate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// validate :: (a -> Bool) -> [a] -> Either e [a]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("validate")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("f")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromPredicate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("这里，根据我们使用 "),a("code",[t._v("map")]),t._v(" 还是 "),a("code",[t._v("traverse")]),t._v("，我们有两个不同的函数。第一个， "),a("code",[t._v("partition")]),t._v(" 将会根据谓词函数给我们一个包含 "),a("code",[t._v("Left")]),t._v(" 和 "),a("code",[t._v("Right")]),t._v(" 的数组。这能够把宝贵的数据保留起来以供未来使用，而不是将它和洗澡水一同过滤掉。相反，"),a("code",[t._v("validate")]),t._v(" 将会给我们一个包含第一个不符合谓词函数的项目的 "),a("code",[t._v("Left")]),t._v("，或者如果一切顺利的话给我们所有的包含对应元素的 "),a("code",[t._v("Right")]),t._v("。通过选择不同的类型顺序，我们得到不同的行为。")]),t._v(" "),a("p",[t._v("让我们看看 "),a("code",[t._v("List")]),t._v(" 的 "),a("code",[t._v("traverse")]),t._v(" 函数，来了解 "),a("code",[t._v("validate")]),t._v(" 是如何形成的。")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" fn")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("this")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("$value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" a")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fn")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("b")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("bs")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" bs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("concat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("b"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("ap")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("List")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),a("p",[t._v("它仅仅是对这个列表运行了一次 "),a("code",[t._v("reduce")]),t._v("。 传入的 reduce 函数是 "),a("code",[t._v("(f, a) => fn(a).map(b => bs => bs.concat(b)).ap(f)")]),t._v("，这看起来有点儿吓人，让我们一步步看。")]),t._v(" "),a("ol",[a("li",[a("p",[a("code",[t._v("reduce(..., ...)")])]),t._v(" "),a("p",[t._v("它的签名是 "),a("code",[t._v("reduce :: [a] -> (f -> a -> f) -> f -> f")]),t._v("。第一个参数事实上是由 "),a("code",[t._v("$value")]),t._v(" 的点标记提供的，它是一个数组。然后我们需要一个函数，以一个 "),a("code",[t._v("f")]),t._v(" (一个累计器) 和一个 a (迭代器，代表当前值) 为输入参数，返回一个新的累计器。")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("of(new List([]))")])]),t._v(" "),a("p",[t._v("reduce 函数的初始值是 "),a("code",[t._v("of(new List([]))")]),t._v("，在我们的例子当中则是 "),a("code",[t._v("Right([]) :: Either e [a]")]),t._v("。注意 "),a("code",[t._v("Either e [a]")]),t._v(" 同时也是我们的最终返回类型。")])]),t._v(" "),a("li",[a("p",[a("code",[t._v("fn::Applicative f => a -> f a")])]),t._v(" "),a("p",[t._v("如果我们把它应用到上面的例子， "),a("code",[t._v("fn")]),t._v(" 实际上是 "),a("code",[t._v("fromPredicate(f) :: a -> Either e a")])]),t._v(" "),a("blockquote",[a("p",[t._v("fn(a) :: Either e a")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v(".map(b => bs => bs.concat(b))")])]),t._v(" "),a("p",[t._v("当 "),a("code",[t._v("fn(a)")]),t._v(" 是一个 "),a("code",[t._v("Right")]),t._v(" 的时候，"),a("code",[t._v("Either.map")]),t._v(" 将正确的值传入函数中并且返回一个包含结果的新的 "),a("code",[t._v("Right")]),t._v("。在这个例子中，函数有一个参数 ("),a("code",[t._v("b")]),t._v(")，并且返回了另一个函数 ("),a("code",[t._v("bs => bs.concat(b)")]),t._v("，其中 "),a("code",[t._v("b")]),t._v(" 由于闭包的存在是在作用域内的。)。当它是一个 "),a("code",[t._v("Left")]),t._v(" 时，Left 对应的值会被返回。")]),t._v(" "),a("blockquote",[a("p",[t._v("fn(a).map(b => bs => bs.concat(b)) :: Either e ([a] -> [a])")])])]),t._v(" "),a("li",[a("p",[a("code",[t._v("ap(f)")])]),t._v(" "),a("p",[a("code",[t._v("f")]),t._v(" 在这里是一个 Applicative，所以我们可以把函数 "),a("code",[t._v("bs => bs.concat(b)")]),t._v(" 应用到 "),a("code",[t._v("f")]),t._v(" 中任意的值 "),a("code",[t._v("bs :: [a]")]),t._v("。幸运的是，"),a("code",[t._v("f")]),t._v(" 是从我们的初始种子得到的，它有这样的类型："),a("code",[t._v("f :: Either e [a]")]),t._v("，这也会在我们应用 "),a("code",[t._v("bs => bs.concat(b)")]),t._v(" 的时候保留下来。当 "),a("code",[t._v("f")]),t._v(" 是 "),a("code",[t._v("Right")]),t._v(" 的时候，它将会调用 "),a("code",[t._v("bs => bs.concat(b)")]),t._v("，返回一个将元素添加到列表中的 "),a("code",[t._v("Right")]),t._v("；当它是个 "),a("code",[t._v("Left")]),t._v(" 的时候，Left 对应的值会被返回。")]),t._v(" "),a("blockquote",[a("p",[t._v("fn(a).map(b => bs => bs.concat(b)).ap(f) :: Either e [a]")])])])]),t._v(" "),a("p",[t._v("这个神奇的转换仅仅通过 "),a("code",[t._v("List.traverse")]),t._v(" 中的 6 行简短的代码实现，并且通过 "),a("code",[t._v("of")]),t._v(", "),a("code",[t._v("map")]),t._v(" 和 "),a("code",[t._v("ap")]),t._v(" 完成，所以它将在任意的 Applicative Functor 中正常工作。这是一个很棒的例子，展示了那些抽象能够如何帮助我们写出高度通用的代码，仅仅依赖于一点点假设（而且这些假设可以通过类型系统声明和检查！）。")]),t._v(" "),a("h2",{attrs:{id:"类型的华尔兹"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#类型的华尔兹"}},[t._v("#")]),t._v(" 类型的华尔兹")]),t._v(" "),a("p",[t._v("是时候重新回顾并且清理我们最开始的例子了。")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// readFile :: FileName -> Task Error String")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// firstWords :: String -> String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" firstWords "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("intercalate")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("take")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("split")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("' '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// tldr :: FileName -> Task Error String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" tldr "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("firstWords"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" readFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Task"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" tldr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'file1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'file2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Task(['hail the monarchy', 'smash the patriarchy']);")]),t._v("\n")])])]),a("p",[t._v("使用 "),a("code",[t._v("traverse")]),t._v(" 而不是 "),a("code",[t._v("map")]),t._v("，我们成功地将那些不守规矩的 "),a("code",[t._v("Task")]),t._v(" 赶到了一个漂亮的、协调的结果数组中。如果你熟悉 "),a("code",[t._v("Promise.all()")]),t._v("，你会发现它们很像；只不过 "),a("code",[t._v("traverse")]),t._v(" 并不是个一次性的自定义函数，它适用于任何可遍历的类型。这些数学上的 API 倾向于以一种互操作、可重用的方式捕获我们想做的大部分事情，而不必像单个类库那样为某一类型重新发明这些函数。")]),t._v(" "),a("p",[t._v("让我们清理最后一个例子来收尾。")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// getAttribute :: String -> Node -> Maybe String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// $ :: Selector -> IO Node")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// getControlNode :: Selector -> IO (Maybe Node)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" getControlNode "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("chain")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("IO")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" $"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getAttribute")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'aria-controls'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  $\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我们用 "),a("code",[t._v("chain(traverse(IO.of, $))")]),t._v("代替 "),a("code",[t._v("map(map($))")]),t._v("，它在映射时反转我们的类型，然后通过 chain 将两个 IO 扁平化。")]),t._v(" "),a("h2",{attrs:{id:"定律"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#定律"}},[t._v("#")]),t._v(" 定律")]),t._v(" "),a("p",[t._v("好了，在你要像法官像敲槌子一样下结论关闭本章之前，还是要认识到，这些定律是很受用的法规保证。在我看来，大多数程序架构的目地是对代码加以限制来缩小可能性，最终引导我们找到正确答案。")]),t._v(" "),a("p",[t._v("一个没有定律的接口是迂回的。像其他的数学结构一样，为了我们自己的理智，我们必须暴露出属性。这和封装有类似的作用，因为它保护了数据，使我们能够用另一个遵守定律的公民来交换接口。")]),t._v(" "),a("p",[t._v("来吧，我们有一些定律要研究。")]),t._v(" "),a("h3",{attrs:{id:"同一律-identity"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#同一律-identity"}},[t._v("#")]),t._v(" 同一律 (Identity)")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" identity1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Identity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Identity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" identity2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Identity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// test it out with Right")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("identity1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'stuff'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Identity(Right('stuff'))")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("identity2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'stuff'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Identity(Right('stuff'))")]),t._v("\n")])])]),a("p",[t._v("这应该是很直接的。如果我们把一个 Identity 放在 functor 中，然后用 "),a("code",[t._v("sequence")]),t._v(" 把它翻出来，这就和一开始就把它放在外面是一样的。我们选择 "),a("code",[t._v("Right")]),t._v(" 作为小白鼠，因为它很容易验证和检查定律。一个任意的 functor 在这里是正常的，然而，在这里使用一个具体的 functor，即定律本身中的 "),a("code",[t._v("Identity")]),t._v("，可能会引起一些人的注意。请记住，一个"),a("RouterLink",{attrs:{to:"/ch5.html#范畴学"}},[t._v("范畴")]),t._v("是由其对象之间的变形来定义的，这些变形具有关联构成和同一性。当处理 functor 的范畴时，自然变换就是形态，而 "),a("code",[t._v("Identity")]),t._v(" 就是，嗯，自身。"),a("code",[t._v("Identity")]),t._v(" functor 和 "),a("code",[t._v("compose")]),t._v(" 函数一样，都是很基本的定律。好了，关于 "),a("code",[t._v("Identity")]),t._v(" 就先到这里，接下来我们看看 "),a("RouterLink",{attrs:{to:"/ch8.html#一点理论"}},[t._v("Compose")]),t._v(" 类型：")],1),t._v(" "),a("h3",{attrs:{id:"组合-composition"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#组合-composition"}},[t._v("#")]),t._v(" 组合 (Composition)")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" comp1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Compose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Compose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("comp2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("Fof"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Gof")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Compose"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Gof"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Fof"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Test it out with some types we have lying around")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("comp1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("Identity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("Right")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Compose(Right([Identity(true)]))")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("comp2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("Identity")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("Right")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Compose(Right([Identity(true)]))")]),t._v("\n")])])]),a("p",[t._v("这个定律如人们所期望的那样保留了组合：如果我们交换 functor 的组合，我们不应该看到任何意外，因为组合本身就是一个 functor。我们任意地选择了 "),a("code",[t._v("true")]),t._v("、"),a("code",[t._v("Right")]),t._v("、"),a("code",[t._v("Identity")]),t._v(" 和 "),a("code",[t._v("Array")]),t._v(" 来测试它。像 "),a("a",{attrs:{href:"https://hackage.haskell.org/package/QuickCheck",target:"_blank",rel:"noopener noreferrer"}},[t._v("quickcheck"),a("OutboundLink")],1),t._v(" 或 "),a("a",{attrs:{href:"http://jsverify.github.io/",target:"_blank",rel:"noopener noreferrer"}},[t._v("jsverify"),a("OutboundLink")],1),t._v(" 这样的库可以通过模糊测试输入来帮助我们测试这个规律。")]),t._v(" "),a("p",[t._v("作为上述定律的自然结果，我们能够获得"),a("a",{attrs:{href:"https://www.cs.ox.ac.uk/jeremy.gibbons/publications/iterator.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("融合遍历"),a("OutboundLink")],1),t._v("的能力，这从性能的角度来看很不错。")]),t._v(" "),a("h3",{attrs:{id:"自然-naturality"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#自然-naturality"}},[t._v("#")]),t._v(" 自然 (Naturality)")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("natLaw1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("natLaw2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sequence")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("nt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// test with a random natural transformation and our friendly Identity/Right functors.")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// maybeToEither :: Maybe a -> Either () a")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("maybeToEither")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("x")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("$value "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Right")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("$value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Left")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("natLaw1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Maybe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" maybeToEither"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Identity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Maybe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'barlow one'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Right(Identity('barlow one'))")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("natLaw2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" maybeToEither"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Identity"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Maybe"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'barlow one'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Right(Identity('barlow one'))")]),t._v("\n")])])]),a("p",[t._v("这和同一律有点像。如果我们先把类型翻转出来，在外部做一次 natural transformation，那将会和 map 一下 natural transformation 然后再翻转类型得到同样的结果。")]),t._v(" "),a("p",[t._v("这个定律的一个自然的结果就是：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[t._v("traverse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("A")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("A")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token constant"}},[t._v("A")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("of"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("从性能的角度看，这也是极好的。")]),t._v(" "),a("h2",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("p",[a("em",[t._v("Traversable")]),t._v(" 是一个强大的接口，能够让你像有心灵感应的室内设计师一样轻松重新编排类型。我们可以通过不同的顺序达到不同的作用，也可以熨平那些令人讨厌的无法 "),a("code",[t._v("join")]),t._v(" 的类型皱纹。接下来，我们将一起欣赏函数式编程乃至于代数学本身最强大的接口之一："),a("RouterLink",{attrs:{to:"/ch13.html"}},[t._v("Monoids")]),t._v("。")],1),t._v(" "),a("h2",{attrs:{id:"练习"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#练习"}},[t._v("#")]),t._v(" 练习")]),t._v(" "),a("p",[t._v("考虑下列元素：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// httpGet :: Route -> Task Error JSON")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// routes :: Map Route Route")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" routes "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string-property property"}},[t._v("'/about'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/about'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("使用 traversable 接口把 "),a("code",[t._v("getJsons")]),t._v(" 的类型签名改成 "),a("code",[t._v("Map Route Route -> Task Error (Map Route JSON)")])]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// getJsons :: Map Route Route -> Map Route (Task Error JSON)")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" getJsons "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("httpGet"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("我们现在定义下列校验函数：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// validate :: Player -> Either String Player")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("validate")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("player")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v("\n  player"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" Either"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("of")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("player"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("left")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'must have name'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("使用 traversable 和 "),a("code",[t._v("validate")]),t._v(" 函数，更新 "),a("code",[t._v("startGame")]),t._v(" （和它的类型签名），使得只有在所有玩家是有效时才开始游戏。")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// startGame :: [Player] -> [Either Error String]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" startGame "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("always")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'game started!'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("validate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("最终，我们考虑一些文件系统相关的帮助函数：")]),t._v(" "),a("div",{staticClass:"language-js extra-class"},[a("pre",{pre:!0,attrs:{class:"language-js"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// readfile :: String -> String -> Task Error String")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// readdir :: String -> Task Error [String]")]),t._v("\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);